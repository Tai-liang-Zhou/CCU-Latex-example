In this section we survey the existing literature related to dialogue models and neural dialogue systems. 
The traditional design of dialogue systems follows a certain modular approach, rule-based chatbots, and retrieval based models. 
In recent years, due to the rising of deep learning (DL) and hardware advances, increasing researchers have focused on the design of chatbots, end-to-end dialogue systems. The tasks of natural language understanding, sentence generator, and the dialogue management are performed by a single deep network that is trained given a large dataset to reproduce conversations. The deep learning system with reinforcement learning would generates a response from a user’s input. The detailed description of the related topics is listed as follows. 
\section{Rule-based Models} \label{subsubsec:Rule-based Modelsg}
The rule-based model is a model can be either very simple or very complex. In \cite{Webb00rule-baseddialogue}, a chatbot answers questions based on pre-defined rules. However, the rule-based chatbot is not efficient in answering a great amount of questions whose patterns do not match with the rules based on which the model is trained. The rule-based chatbot can handle simple questions, but it fails to manage complex questions.
\section{Retrieval-based Models}\label{subsubsec:Retrieval-based Models}
The retrieval-based model is trained given a lot of questions and their possible answers. Although a retrieval-based chatbot is trained given a dataset with a large amount of questions and answers, the chatbot cannot generate a new sentence that is not in the training dataset. In addition, the retrieval-based model \cite{Retrieval-based_Dialogue_System} uses the natural language understand (NLU) module to process the user’s speech as input, extract key values and the useful features that can be used by the dialogue system to update neural network’s parameters, and then send queries to a historical dialogue database. In general, there are two approaches applying retrieval based models to a task-oriented dialog system. The first approach adopting end-to-end learning of ask task-oriented dialog systems is called hybrid code networks \cite{HCN}. Hybrid code networks (HCNs) support a separation of concerns where procedural knowledge and constraints can be expressed in software, and the control flow. Compared to the existing end-to-end approaches, HCNs provide developers more control and require less training data so as to reduce the development cost. The second approach applies end-to-end task-completion neural dialogue systems \cite{End-to-End_Task-Completion_Neural_Dialogue_Systems} which utilize an end-to-end learning framework for task-completion neural dialogue systems. Furthermore, both for simulated and real users, the results show that reinforcement learning systems outperform rule-based agents, and have better robustness to allow natural interactions with users in real-world task-completion scenarios. The end-to-end task-completion neural dialogue systems conduct a series of extensive experiments to understand the impact of natural language understanding errors on the performance of a task-completion neural dialogue system based on reinforcement learning
\section{Generative Models}\label{subsubsec:Generative Models}
Unlike rule-based models, the generative models \cite{Deep_Reinforcement_Learning_for_Dialogue_Generation} can generate various answers that are not limited to a set of pre-defined answers. A generative model is intelligent as it takes word by word from the query and generates the answers. However, such a model is also prone to errors as it needs to take the spelling and grammar into account. To handling these errors, these models need to be trained more precisely. The most common generative model is the sequence-to-sequence model \cite{Sequence_to_sequence_learning_with_neural_networks}. However, the sentence generated by the sequence-to-sequence model are very simple, repetitive, and dull. To handle those problems, the reinforcement learning and adversarial learning neural network framework were proposed. Generative adversarial networks have enjoyed great success in computer vision. However, this method has not achieved comparable success in sentence generation. The first work \cite{SeqGAN} extending generative adversarial network (GANs) to generate dialogues is SeqGAN, which effectively trains generative adversarial nets for structured sequence generation via policy gradient. For three real-world scenarios, \ie, poems, speech language and music generation, SeqGAN achieves excellent performance on generating the creative sequences. Moreover, the same approach was proposed on adversarial learning for neural dialogue generation \cite{Adversarial_Learning_for_Neural_Dialogue_Generation}. Adversarial learning for neural dialogue generation casts the model in the framework of reinforcement learning and trains a generator based on the signal from a discriminator to generate response sequences indistinguishable from human-generated dialogues. To enhance the dialogue generation model, Serban \etal proposed a hierarchical recurrent encoder-decoder (HRED) neural network \cite{Hierarchical_Neural_Network_Generative_Models_for_Movie_Dialogues}, which was implemented to enhance the traditional RNN model for the following reasons. The context-based encoding allows the model to obtain the association rules between two sentences. Second, the HRED-based neural network model reduces computational steps between utterances. This helps propagate the training signal for first-order optimization methods. However, traditional generation models have two controversial issues. First, the outputs that response with the greatest likelihood are frequently vague or non-committal \cite{A_Diversity-Promoting_Objective_Function_for_Neural_Conversation_Models}. Second, the speakers and users are wildly inconsistent. Li \etal addressed the challenge of consistency and how to endow a dialogue system with the coherent persona-based model. By encoding personas information in the model, the conversation system can be demonstrated with a speaking style and background information. Recent research related to generative models has focused on creating models to generate information, non-redundant context, and diverse text. A diversity-promoting generative adversarial network (DP-GAN) \cite{DP-GAN}, which is used for diversified text generation assigns low rewards for repeated text and high rewards for the novel text. The reward mechanism consists of sentence-level and word-level rewards. A novel language-model-based discriminator, which can better distinguish novel text from repeated text without the saturation problem, was compared with the existing classifier-based discriminators. The experimental results on dialogue generation tasks show that the method can generate substantially more diverse and informative text than the existing methods.